{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIGIRpreprocessingFlau.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/xUiBt8+R1RScHEaI5uDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakina8/Multimodal-Classification2020/blob/master/SIGIRpreprocessingFlau.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kLHIToLPwyi"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "import time, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import logging\n",
        "tqdm.pandas()\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zGQVy-Lv4XB",
        "outputId": "f0b76a3b-6754-4a10-cf32-d8f11ca37bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KHJF0X03qFg",
        "outputId": "f8c57ed8-7735-462c-c78c-05e1bc6723ca",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b3434e0-f918-47ea-907b-0fd13187c0fa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b3434e0-f918-47ea-907b-0fd13187c0fa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving catalog_english_taxonomy.tsv to catalog_english_taxonomy.tsv\n",
            "Saving x_test_task1_phase1.tsv to x_test_task1_phase1.tsv\n",
            "Saving x_test_task2_phase1.tsv to x_test_task2_phase1.tsv\n",
            "Saving X_train.tsv to X_train.tsv\n",
            "Saving Y_train.tsv to Y_train.tsv\n",
            "User uploaded file \"catalog_english_taxonomy.tsv\" with length 416 bytes\n",
            "User uploaded file \"x_test_task1_phase1.tsv\" with length 48228 bytes\n",
            "User uploaded file \"x_test_task2_phase1.tsv\" with length 49075 bytes\n",
            "User uploaded file \"X_train.tsv\" with length 64569 bytes\n",
            "User uploaded file \"Y_train.tsv\" with length 3088 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35Lm4GEah5Ia"
      },
      "source": [
        " #loading the train data and test data\n",
        "catalog_eng = pd.read_csv(\"catalog_english_taxonomy.tsv\",sep=\"\\t\")\n",
        "X_train = pd.read_csv(\"X_train.tsv\",sep=\"\\t\")\n",
        "Y_train = pd.read_csv(\"Y_train.tsv\",sep=\"\\t\")\n",
        "list_tags = list(Y_train['Prdtypecode'].unique())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qxOoBNGiSMo",
        "outputId": "82ec09dd-cb84-4962-ddfb-25c04dd76bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "catalog_eng.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prdtypecode</th>\n",
              "      <th>Top level category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1280</td>\n",
              "      <td>Child</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1281</td>\n",
              "      <td>Child</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1920</td>\n",
              "      <td>Household</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1160</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Books</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Prdtypecode Top level category\n",
              "0         1280              Child\n",
              "1         1281              Child\n",
              "2         1920          Household\n",
              "3         1160      Entertainment\n",
              "4           10              Books"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EqJAe37iZsa",
        "outputId": "12e9740d-a878-4633-80ff-3eb84b7662c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1263597046</td>\n",
              "      <td>3804725264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1008141237</td>\n",
              "      <td>436067568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
              "      <td>938777978</td>\n",
              "      <td>201115110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>457047496</td>\n",
              "      <td>50418756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>La Guerre Des Tuques</td>\n",
              "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
              "      <td>1077757786</td>\n",
              "      <td>278535884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Integer_id  ...  Product_id\n",
              "0           0  ...  3804725264\n",
              "1           1  ...   436067568\n",
              "2           2  ...   201115110\n",
              "3           3  ...    50418756\n",
              "4           4  ...   278535884\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guxaMP4XigLY",
        "outputId": "a55633c7-af43-427b-e72c-e0d151da5df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "list_tags"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10,\n",
              " 2280,\n",
              " 50,\n",
              " 1280,\n",
              " 2705,\n",
              " 2522,\n",
              " 2582,\n",
              " 1560,\n",
              " 1281,\n",
              " 1920,\n",
              " 2403,\n",
              " 1140,\n",
              " 2583,\n",
              " 1180,\n",
              " 1300,\n",
              " 2462,\n",
              " 1160,\n",
              " 2060,\n",
              " 40,\n",
              " 60,\n",
              " 1320,\n",
              " 1302,\n",
              " 2220]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6uYRzp6irU7"
      },
      "source": [
        " dict_code_to_id = {}\n",
        " dict_id_to_code = {}\n",
        "\n",
        " \n",
        " for i,tag in enumerate(list_tags):\n",
        "                dict_code_to_id[tag] = i \n",
        "                dict_id_to_code[i]=tag\n",
        "                "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb6mnpprjEYR",
        "outputId": "9e9a2e4a-63ee-481e-ed6c-6723c99be288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#map \n",
        "Y_train['labels']=Y_train['Prdtypecode'].map(dict_code_to_id)\n",
        "Y_train.head(7)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdtypecode</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1263597046</td>\n",
              "      <td>3804725264</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1008141237</td>\n",
              "      <td>436067568</td>\n",
              "      <td>2280</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>938777978</td>\n",
              "      <td>201115110</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>457047496</td>\n",
              "      <td>50418756</td>\n",
              "      <td>1280</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1077757786</td>\n",
              "      <td>278535884</td>\n",
              "      <td>2705</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>393356830</td>\n",
              "      <td>5862738</td>\n",
              "      <td>2280</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>907794536</td>\n",
              "      <td>91920807</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Integer_id    Image_id  Product_id  Prdtypecode  labels\n",
              "0           0  1263597046  3804725264           10       0\n",
              "1           1  1008141237   436067568         2280       1\n",
              "2           2   938777978   201115110           50       2\n",
              "3           3   457047496    50418756         1280       3\n",
              "4           4  1077757786   278535884         2705       4\n",
              "5           5   393356830     5862738         2280       1\n",
              "6           6   907794536    91920807           10       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf5M4wiZjW4P",
        "outputId": "5adfc4c4-d999-43ae-e360-a6ed4674479c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#merge the train\n",
        "train=pd.merge(left=X_train,right=Y_train,\n",
        "              how='left',left_on=['Integer_id','Image_id','Product_id'],\n",
        "              right_on=['Integer_id','Image_id','Product_id'])\n",
        "prod_map=pd.Series(catalog_eng['Top level category'].values,\n",
        "                  index=catalog_eng['Prdtypecode']).to_dict()\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdtypecode</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1263597046</td>\n",
              "      <td>3804725264</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1008141237</td>\n",
              "      <td>436067568</td>\n",
              "      <td>2280</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
              "      <td>938777978</td>\n",
              "      <td>201115110</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>457047496</td>\n",
              "      <td>50418756</td>\n",
              "      <td>1280</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>La Guerre Des Tuques</td>\n",
              "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
              "      <td>1077757786</td>\n",
              "      <td>278535884</td>\n",
              "      <td>2705</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Integer_id  ... labels\n",
              "0           0  ...      0\n",
              "1           1  ...      1\n",
              "2           2  ...      2\n",
              "3           3  ...      3\n",
              "4           4  ...      4\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9RlQRoCjXU5",
        "outputId": "321cd6ee-1008-4744-e36e-f8ae993bccfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "prod_map"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'Books',\n",
              " 40: 'Entertainment',\n",
              " 50: 'Entertainment',\n",
              " 60: 'Entertainment',\n",
              " 1140: 'Entertainment',\n",
              " 1160: 'Entertainment',\n",
              " 1180: 'Entertainment',\n",
              " 1280: 'Child',\n",
              " 1281: 'Child',\n",
              " 1300: 'Child',\n",
              " 1301: 'Child',\n",
              " 1302: 'Child',\n",
              " 1320: 'Child',\n",
              " 1560: 'Household',\n",
              " 1920: 'Household',\n",
              " 1940: 'Household',\n",
              " 2060: 'Household',\n",
              " 2220: 'Household',\n",
              " 2280: 'Books',\n",
              " 2403: 'Books',\n",
              " 2462: 'Entertainment',\n",
              " 2522: 'Books',\n",
              " 2582: 'Household',\n",
              " 2583: 'Household',\n",
              " 2585: 'Household',\n",
              " 2705: 'Books',\n",
              " 2905: 'Entertainment'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkQbxFLrj8nP",
        "outputId": "fd481e95-32aa-4b53-c21e-fbf9cf6c0f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "#creating the mapping\n",
        "train['product'] = train['Prdtypecode'].map(prod_map)\n",
        "train['desc_len']=train['Description'].progress_apply(lambda x : len(x.split()) if pd.notna(x) else 0)\n",
        "\n",
        "train.loc[train['Description'].isnull(), 'Description'] = \" \"\n",
        "train['title_desc'] = train['Title'] + \" \" + train['Description']\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 101/101 [00:00<00:00, 15513.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdtypecode</th>\n",
              "      <th>labels</th>\n",
              "      <th>product</th>\n",
              "      <th>desc_len</th>\n",
              "      <th>title_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "      <td></td>\n",
              "      <td>1263597046</td>\n",
              "      <td>3804725264</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>Books</td>\n",
              "      <td>0</td>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td></td>\n",
              "      <td>1008141237</td>\n",
              "      <td>436067568</td>\n",
              "      <td>2280</td>\n",
              "      <td>1</td>\n",
              "      <td>Books</td>\n",
              "      <td>0</td>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
              "      <td>938777978</td>\n",
              "      <td>201115110</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>109</td>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "      <td></td>\n",
              "      <td>457047496</td>\n",
              "      <td>50418756</td>\n",
              "      <td>1280</td>\n",
              "      <td>3</td>\n",
              "      <td>Child</td>\n",
              "      <td>0</td>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>La Guerre Des Tuques</td>\n",
              "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
              "      <td>1077757786</td>\n",
              "      <td>278535884</td>\n",
              "      <td>2705</td>\n",
              "      <td>4</td>\n",
              "      <td>Books</td>\n",
              "      <td>34</td>\n",
              "      <td>La Guerre Des Tuques Luc a des id&amp;eacute;es de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Integer_id  ...                                         title_desc\n",
              "0           0  ...  Olivia: Personalisiertes Notizbuch / 150 Seite...\n",
              "1           1  ...  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...\n",
              "2           2  ...  Grand Stylet Ergonomique Bleu Gamepad Nintendo...\n",
              "3           3  ...  Peluche Donald - Europe - Disneyland 2000 (Mar...\n",
              "4           4  ...  La Guerre Des Tuques Luc a des id&eacute;es de...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymism3sVsOAS"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "class SigirPreprocess():\n",
        "    \n",
        "    \n",
        "    def __init__(self, text_data_path):\n",
        "        self.text_data_path = text_data_path\n",
        "        self.train = None\n",
        "        self.dict_code_to_id = {}\n",
        "        self.dict_id_to_code = {}\n",
        "        self.list_tags = {}\n",
        "        self.sentences = []\n",
        "        self.labels = []\n",
        "        self.text_col = None\n",
        "        self.X_test = None\n",
        "\n",
        "    def prepare_data(self ):\n",
        "        \n",
        "        #loading the train data and test data\n",
        "      catalog_eng = pd.read_csv(self.text_data_path+\"data/catalog_english_taxonomy.tsv\",sep=\"\\t\")\n",
        "      X_train= pd.read_csv(self.text_data_path+\"data/X_train.tsv\",sep=\"\\t\")\n",
        "      Y_train= pd.read_csv(self.text_data_path+\"data/Y_train.tsv\",sep=\"\\t\")\n",
        "      self.list_tags = list(Y_train['Prdtypecode'].unique())\n",
        "        \n",
        "      for i,tag in enumerate(self.list_tags):\n",
        "            self.dict_code_to_id[tag] = i \n",
        "            self.dict_id_to_code[i]=tag\n",
        "        \n",
        "        #map \n",
        "      Y_train['labels']=Y_train['Prdtypecode'].map(self.dict_code_to_id)\n",
        "        \n",
        "        #merge the train\n",
        "      train=pd.merge(left=X_train,right=Y_train,\n",
        "               how='left',left_on=['Integer_id','Image_id','Product_id'],\n",
        "               right_on=['Integer_id','Image_id','Product_id'])\n",
        "      prod_map=pd.Series(catalog_eng['Top level category'].values,\n",
        "                           index=catalog_eng['Prdtypecode']).to_dict()\n",
        "        \n",
        "        #creating the mapping\n",
        "      train['product'] = train['Prdtypecode'].map(prod_map)\n",
        "      train['title_len']=train['Title'].progress_apply(lambda x : len(x.split()) if pd.notna(x) else 0)\n",
        "      train['desc_len']=train['Description'].progress_apply(lambda x : len(x.split()) if pd.notna(x) else 0)\n",
        "      train['title_desc_len']=train['title_len'] + train['desc_len']\n",
        "      train.loc[train['Description'].isnull(), 'Description'] = \" \"\n",
        "      train['title_desc'] = train['Title'] + \" \" + train['Description']\n",
        "        \n",
        "      self.train = train\n",
        "  \n",
        "    def get_sentences(self, text_col, remove_null_rows=False):\n",
        "        self.text_col = text_col\n",
        "        if remove_null_rows==True:\n",
        "            new_train = self.train[self.train[text_col].notnull()]\n",
        "\n",
        "        else:\n",
        "            new_train = self.train.copy()\n",
        "            \n",
        "        self.sentences = new_train[text_col].values\n",
        "        self.labels = new_train['labels'].values\n",
        "    \n",
        "    def prepare_test(self, text_col):\n",
        "        X_test=pd.read_csv(self.text_data_path+\"x_test_task1_phase1.tsv\",sep=\"\\t\")\n",
        "        X_test.loc[X_test['Description'].isnull(), 'Description'] = \" \"\n",
        "        X_test['title_desc'] = X_test['Title'] + \" \" + X_test['Description']\n",
        "        self.X_test = X_test\n",
        "        self.test_sentences = X_test[text_col].values"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaEjvVx0CSxr",
        "outputId": "29d2e4d9-c070-4a11-ae1a-cb890d088b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "x_test_task1_phase1 = pd.read_csv(\"x_test_task1_phase1.tsv\", sep=\"\\t\" )\n",
        "x_test_task1_phase1.head(3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Jeep Police - Gevarm-Gevarm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1193217616</td>\n",
              "      <td>3136702026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Court Joyeux Noël En Peluche Taie Sofa Set Pad...</td>\n",
              "      <td>Joyeux Noël en peluche court Taie Sofa Set Pad...</td>\n",
              "      <td>1323615566</td>\n",
              "      <td>4231863665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sauna infrarouge Largo - 170 x 105 x 190 - Pin...</td>\n",
              "      <td>Dimensions : 150x105x190 cm ou 170x105x190 cm ...</td>\n",
              "      <td>1158121321</td>\n",
              "      <td>2695198357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Integer_id  ...  Product_id\n",
              "0           0  ...  3136702026\n",
              "1           1  ...  4231863665\n",
              "2           2  ...  2695198357\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2nwYScwQyxa",
        "outputId": "ec74d7ee-9533-4fdc-deb4-a0f9bc72cb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "X_test=pd.read_csv(\"x_test_task1_phase1.tsv\",sep=\"\\t\")\n",
        "X_test.loc[X_test['Description'].isnull(), 'Description'] = \" \"\n",
        "X_test['title_desc'] = X_test['Title'] + \" \" + X_test['Description']\n",
        "X_test.head(3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>title_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Jeep Police - Gevarm-Gevarm</td>\n",
              "      <td></td>\n",
              "      <td>1193217616</td>\n",
              "      <td>3136702026</td>\n",
              "      <td>Jeep Police - Gevarm-Gevarm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Court Joyeux Noël En Peluche Taie Sofa Set Pad...</td>\n",
              "      <td>Joyeux Noël en peluche court Taie Sofa Set Pad...</td>\n",
              "      <td>1323615566</td>\n",
              "      <td>4231863665</td>\n",
              "      <td>Court Joyeux Noël En Peluche Taie Sofa Set Pad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sauna infrarouge Largo - 170 x 105 x 190 - Pin...</td>\n",
              "      <td>Dimensions : 150x105x190 cm ou 170x105x190 cm ...</td>\n",
              "      <td>1158121321</td>\n",
              "      <td>2695198357</td>\n",
              "      <td>Sauna infrarouge Largo - 170 x 105 x 190 - Pin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Integer_id  ...                                         title_desc\n",
              "0           0  ...                      Jeep Police - Gevarm-Gevarm  \n",
              "1           1  ...  Court Joyeux Noël En Peluche Taie Sofa Set Pad...\n",
              "2           2  ...  Sauna infrarouge Largo - 170 x 105 x 190 - Pin...\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Frgb8tPSxi7"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F78tzequM9L"
      },
      "source": [
        "text_col = 'title_desc'\n",
        "max_len = 256\n",
        "val_size = 0.1\n",
        "\n",
        "# model_str_dict = {'c':'camembert',\n",
        "#                  'f':'flaubert'}\n",
        "# # 'f' for flaubert & 'c' for camembert\n",
        "# case='f' \n",
        "# model_str = model_str_dict[case]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72B4xDxuuNTR",
        "outputId": "50708b4a-f08a-4d88-d221-512770dffb0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "Preprocess = SigirPreprocess(\"catalog_english_taxonomy.tsv\")\n",
        "Preprocess.prepare_data()\n",
        "Preprocess.get_sentences(text_col, True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4b4343824ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPreprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSigirPreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"catalog_english_taxonomy.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mPreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-d19cf6c3efee>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#loading the train data and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mcatalog_eng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_data_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"data/catalog_english_taxonomy.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_data_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"data/X_train.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_data_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"data/Y_train.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'catalog_english_taxonomy.tsvdata/catalog_english_taxonomy.tsv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX9IhC-I8xgz"
      },
      "source": [
        "X_test=pd.read_csv(\"x_test_task1_phase1.tsv\",sep=\"\\t\")\n",
        "X_test.loc[X_test['Description'].isnull(), 'Description'] = \" \"\n",
        "X_test['title_desc'] = X_test['Title'] + \" \" + X_test['Description']\n",
        "test_sentences = X_test[text_col].values"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwy7-Onz9hbP",
        "outputId": "50115c68-ee7e-4a66-bc11-37a37fd82ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "X_test.head(3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>title_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Jeep Police - Gevarm-Gevarm</td>\n",
              "      <td></td>\n",
              "      <td>1193217616</td>\n",
              "      <td>3136702026</td>\n",
              "      <td>Jeep Police - Gevarm-Gevarm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Court Joyeux Noël En Peluche Taie Sofa Set Pad...</td>\n",
              "      <td>Joyeux Noël en peluche court Taie Sofa Set Pad...</td>\n",
              "      <td>1323615566</td>\n",
              "      <td>4231863665</td>\n",
              "      <td>Court Joyeux Noël En Peluche Taie Sofa Set Pad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sauna infrarouge Largo - 170 x 105 x 190 - Pin...</td>\n",
              "      <td>Dimensions : 150x105x190 cm ou 170x105x190 cm ...</td>\n",
              "      <td>1158121321</td>\n",
              "      <td>2695198357</td>\n",
              "      <td>Sauna infrarouge Largo - 170 x 105 x 190 - Pin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Integer_id  ...                                         title_desc\n",
              "0           0  ...                      Jeep Police - Gevarm-Gevarm  \n",
              "1           1  ...  Court Joyeux Noël En Peluche Taie Sofa Set Pad...\n",
              "2           2  ...  Sauna infrarouge Largo - 170 x 105 x 190 - Pin...\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwhbhRuHtHMR",
        "outputId": "f188299e-1a64-4f45-8ba2-98c3cc1d92a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences = Preprocess.sentences\n",
        "labels = Preprocess.labels\n",
        "print(\"Total number of sentences:{}, labels:{}\".format(len(sentences), len(labels)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of sentences:0, labels:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-uR4JNmlpjs"
      },
      "source": [
        "\n",
        "# sns.countplot(x='product', data=self.train)\n",
        "# sns.countplot(x='Prdtypecode', data=self.train)\n",
        "# sns.distplot(Preprocess.train['title_len'])\n",
        "# sns.distplot(Preprocess.train['title_desc_len'])\n",
        "# np.percentile(Preprocess.train['title_desc_len'], 99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ZXW4Fnk6Qf"
      },
      "source": [
        "len(Preprocess.dict_code_to_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RwC3s1pgt8X"
      },
      "source": [
        "#NN Packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, random_split,DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKSNCLC-gt4l"
      },
      "source": [
        "from transformers import XLMForSequenceClassification\n",
        "from transformers import FlaubertModel, FlaubertTokenizer,FlaubertForSequenceClassification,AdamW, FlaubertConfig \n",
        "from torch.nn import Dropout,Conv1d, Linear\n",
        "from transformers.modeling_utils import SequenceSummary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDDewSXOgtwl"
      },
      "source": [
        "# a1 = sentences[0]\n",
        "# max_len = 40\n",
        "# modelname = 'flaubert-base-cased'\n",
        "# tokenizer = FlaubertTokenizer.from_pretrained(modelname, do_lowercase=False)\n",
        "\n",
        "# encoded_dict = tokenizer.encode_plus(\n",
        "#                             a1,                      # Sentence to encode.\n",
        "#                             add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "#                             max_length = max_len,           # Pad & truncate all sentences.\n",
        "#                             pad_to_max_length = True,\n",
        "#                             return_attention_mask = True,   # Construct attn. masks.\n",
        "#                             return_tensors = 'pt',     # Return pytorch tensors.\n",
        "#                        )\n",
        "\n",
        "\n",
        "# iid = encoded_dict['input_ids']\n",
        "# mask = encoded_dict['attention_mask']\n",
        "\n",
        "# iid,mask\n",
        "\n",
        "# # modelname = 'flaubert-base-cased'\n",
        "\n",
        "# model = CustFlaubertForSequenceClassification.from_pretrained(\n",
        "#         modelname, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "#         # num_labels = len(Preprocess.dict_code_to_id), # The number of output labels--2 for binary classification.\n",
        "#         # You can increase this for multi-class tasks.   \n",
        "#         output_attentions = False, # Whether the model returns attentions weights.\n",
        "#         output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "# )\n",
        "\n",
        "# outputs, embed1 = model(iid, token_type_ids=None, attention_mask=mask, \n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGIvvhneemsG"
      },
      "source": [
        "# #max length after tokenization\n",
        "# _max_len = 0\n",
        "# # For every sentence...\n",
        "# for sent in tqdm(sentences):\n",
        "\n",
        "#     # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "#     input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "#     # Update the maximum sentence length.\n",
        "#     _max_len = max(_max_len, len(input_ids))\n",
        "\n",
        "# print('Max sentence length: ', _max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUysVUJWenBZ"
      },
      "source": [
        "modelname = 'flaubert-base-cased'\n",
        "tokenizer = FlaubertTokenizer.from_pretrained(modelname, do_lowercase=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz820BcgtE1L"
      },
      "source": [
        "#function to prepare input for model training\n",
        "def prep_input(sentences,labels, max_len):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in tqdm(sentences):\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_len,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    if labels is not None:\n",
        "        labels = torch.tensor(labels)\n",
        "        return input_ids,attention_masks,labels\n",
        "    else:\n",
        "        return input_ids,attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9nGg5YQtEvq"
      },
      "source": [
        "input_ids,attention_masks,labels=prep_input(sentences,labels, max_len=max_len)\n",
        "# print('Original: ', sentences[0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kLLpxSBtEmQ"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "\n",
        "#Validation split\n",
        "tr_inputs, val_inputs, tr_labels, val_labels = train_test_split(input_ids, labels,stratify=labels,\n",
        "                                                            random_state=2020, test_size=val_size)\n",
        "\n",
        "\n",
        "tr_masks, val_masks, u,v =   train_test_split(attention_masks, labels,stratify=labels,\n",
        "                                             random_state=2020, test_size=val_size)\n",
        "\n",
        "\n",
        "train_dataset=TensorDataset(tr_inputs, tr_masks, tr_labels)\n",
        "val_dataset=TensorDataset(val_inputs, val_masks, val_labels)\n",
        "train_sampler = RandomSampler(train_dataset) \n",
        "valid_sampler = SequentialSampler(val_dataset)\n",
        "\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = train_sampler, # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = valid_sampler, # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BQI9FPdtn3C"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_YbR5Ubtol9"
      },
      "source": [
        "\n",
        "num_classes = 27"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpzOLXOotpbW"
      },
      "source": [
        "class vec_output_FlaubertForSequenceClassification(FlaubertModel):\n",
        "    \n",
        "    config_class = FlaubertConfig\n",
        "    \n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.transformer = FlaubertModel(config)\n",
        "        self.sequence_summary = SequenceSummary(config)\n",
        "        self.init_weights()\n",
        "        self.dropout =  torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_classes)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        langs=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        lengths=None,\n",
        "        cache=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "        \n",
        "        \n",
        "        transformer_outputs = self.transformer(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            langs=langs,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            lengths=lengths,\n",
        "            cache=cache,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        #output = self.dropout(output)\n",
        "        output = transformer_outputs[0]\n",
        "        vec = output[:,0]\n",
        "        \n",
        "        \n",
        "        #logits\n",
        "        dense = self.dropout(vec)\n",
        "        \n",
        "        #classifier\n",
        "        logits = self.classifier(dense)\n",
        "        \n",
        "        outputs = (logits,) + transformer_outputs[1:]  # Keep new_mems and attention/hidden states if they are here\n",
        "        \n",
        "        return outputs,dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOHEnFZUtpAN"
      },
      "source": [
        "len(Preprocess.dict_code_to_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8KUrSnVtoT9"
      },
      "source": [
        "modelname = 'flaubert-base-cased'\n",
        "\n",
        "model = vec_output_FlaubertForSequenceClassification.from_pretrained(\n",
        "        modelname, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels = len(Preprocess.dict_code_to_id), # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.   \n",
        "        output_attentions = False, # Whether the model returns attentions weights.\n",
        "        output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXAeG0IftnTo"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbNTFnp3uIRc"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 12\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvc5n02BuIXX"
      },
      "source": [
        "import torch.nn as nn\n",
        "loss_criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp6VzBN5uHHS"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    \n",
        "    #tr and val\n",
        "    vec_output_tr = []\n",
        "    vec_output_val =[]\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    best_f1 = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        logits,vec = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask\n",
        "                    )\n",
        "        #new\n",
        "        logits = logits[0]\n",
        "        \n",
        "        #Defining the loss\n",
        "        loss = loss_criterion(logits, b_labels)\n",
        "        \n",
        "        #saving the features_tr\n",
        "        vec = vec.detach().cpu().numpy()\n",
        "        vec_output_tr.extend(vec)\n",
        "        \n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f} \".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:} \".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    predictions=[]\n",
        "    true_labels=[]\n",
        "    \n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            logits,vec = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask\n",
        "                           )\n",
        "            \n",
        "        #new\n",
        "        logits = logits[0]\n",
        "        \n",
        "        #defining the val loss\n",
        "        loss = loss_criterion(logits, b_labels)\n",
        "        \n",
        "        \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        predicted_labels=np.argmax(logits,axis=1)\n",
        "        predictions.extend(predicted_labels)\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        true_labels.extend(label_ids)\n",
        "        \n",
        "        #saving the features_tr\n",
        "        vec = vec.detach().cpu().numpy()\n",
        "        vec_output_val.extend(vec)\n",
        "        \n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    print(\"Validation F1-Score: {}\".format(f1_score(true_labels,predictions,average='macro')))\n",
        "    curr_f1=f1_score(true_labels,predictions,average='macro')\n",
        "    if curr_f1 > best_f1:\n",
        "        best_f1=curr_f1\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        np.save('best_vec_train.npy',vec_output_tr)\n",
        "        np.save('best_vec_val.npy',vec_output_val)\n",
        "    # Record all statistics from this epoch.\n",
        "#     training_stats.append(\n",
        "#         {\n",
        "#             'epoch': epoch_i + 1,\n",
        "#             'Training Loss': avg_train_loss,\n",
        "#             'Valid. Loss': avg_val_loss,\n",
        "#             'Valid. Accur.': avg_val_accuracy,\n",
        "#             'Training Time': training_time,\n",
        "#             'Validation Time': validation_time\n",
        "#         }\n",
        "#     )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MhKOckSuHcA"
      },
      "source": [
        "# Save model\n",
        "# try:\n",
        "#     model_state = {'model': model,\n",
        "#               'state_dict': model.state_dict(),\n",
        "#               'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "#     torch.save(model_state, 'saved_model.pth')\n",
        "# except:\n",
        "#     print('Error in saving model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD2c40o0ujMl"
      },
      "source": [
        "##Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfsjqw3muHWG"
      },
      "source": [
        "model_path = '/../working/best_model.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcx-q_WaenLp"
      },
      "source": [
        "## Change the **model path** accordingly\n",
        "# model_str = 'flaubert'\n",
        "# model_path_dict = {'camembert':'/../input/camembertvinodh/saved_model.pth',\n",
        "#                   'flaubert':'/../input/flaubertekansh/saved_model.pth'}\n",
        "\n",
        "# model_path = model_path_dict[model_str]\n",
        "checkpoint = torch.load(model_path)\n",
        "# model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMKIMZhxuxK1"
      },
      "source": [
        "def predict_pyt(model, prediction_dataloader):\n",
        "    \"\"\"\n",
        "    model: pytorch model\n",
        "    prediction_dataloader: DataLoader object for which the predictions has to be made.\n",
        "    return:\n",
        "        predictions:- Direct predicted labels\n",
        "        softmax_logits:- logits which are normalized with softmax on output\"\"\"\n",
        "    \n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions = []\n",
        "    softmax_logits=[]\n",
        "    vec_outputs = []\n",
        "    \n",
        "    # Predict \n",
        "    for batch in prediction_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        try:\n",
        "            b_input_ids, b_input_mask = batch\n",
        "        except ValueError:\n",
        "            b_input_ids, b_input_mask, _ = batch\n",
        "        # Telling the model not to compute or store gradients, saving memory and \n",
        "        # speeding up prediction\n",
        "        with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "            logits,vec = model(b_input_ids, token_type_ids=None, \n",
        "                          attention_mask=b_input_mask)\n",
        "            \n",
        "            logits = logits[0]\n",
        "\n",
        "        \n",
        "    #----- Add softmax---     \n",
        "        m = nn.Softmax(dim=1)\n",
        "    # #     input = torch.randn(2, 3)\n",
        "        output = m(logits)\n",
        "    #-------#------\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        predicted_labels=np.argmax(logits,axis=1)\n",
        "        predictions.extend(predicted_labels)\n",
        "        softmax_logits.extend(output)\n",
        "        \n",
        "        #vec_outputs saving\n",
        "        vec = vec.detach().cpu().numpy()\n",
        "        vec_outputs.extend(vec)\n",
        "\n",
        "    print('DONE')\n",
        "    return predictions, softmax_logits , vec_outputs\n",
        "\n",
        "def predict_wrapper(model, sentences, max_len=max_len, batch_size = batch_size ):\n",
        "    \"\"\"\n",
        "    Wrapper to create DataLoader object and predict, \n",
        "    this is if model and sentences are passed\"\"\"\n",
        "    input_ids,attention_masks=prep_input(sentences,labels=None, max_len=max_len)\n",
        "    prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "    prediction_sampler = SequentialSampler(prediction_data)\n",
        "    prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "    return predict_pyt(model, prediction_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3TjzPoVuxln"
      },
      "source": [
        "## Prepare the test dataset\n",
        "batch_size = 32  \n",
        "\n",
        "Preprocess.prepare_test(text_col)\n",
        "test_sentences = Preprocess.test_sentences\n",
        "X_test_phase1= Preprocess.X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nohfQmdOuxjA"
      },
      "source": [
        "# Predictions of validation set which is randomly separated from train dataset\n",
        "start = time.time()\n",
        "predictions, val_softmax_logits , vec_outputs= predict_pyt(model, validation_dataloader)\n",
        "val_softmax_logits = np.array([ten.detach().cpu().numpy() for ten in val_softmax_logits])\n",
        "np.save('validation_set_softmax_logits.npy',val_softmax_logits)\n",
        "print('Time Taken Predict for val set: {:}'.format(format_time(time.time() - start)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX4WF3wruxgM"
      },
      "source": [
        "## Predictions of test dataset \n",
        "\n",
        "start = time.time()\n",
        "predictions, softmax_logits , vec_outputs = predict_wrapper(model, test_sentences)\n",
        "\n",
        "#saving\n",
        "np.save('best_vec_test.npy',vec_outputs)\n",
        "softmax_logits = np.array([ten.detach().cpu().numpy() for ten in softmax_logits])\n",
        "np.save('X_test_phase1_softmax_logits.npy',softmax_logits)\n",
        "print('length of predictions {}'.format(len(predictions)))\n",
        "print('Time Taken Predict for val set: {:}'.format(format_time(time.time() - start) ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaxBPfzmuxbG"
      },
      "source": [
        "X_test_phase1['prediction_model']= predictions\n",
        "X_test_phase1['Prdtypecode']=X_test_phase1['prediction_model'].map(Preprocess.dict_id_to_code)\n",
        "print(X_test_phase1['Prdtypecode'].value_counts())\n",
        "X_test_phase1=X_test_phase1.drop(['prediction_model','Title','Description'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxIpH_RWuxXv"
      },
      "source": [
        "X_test_phase1.to_csv('y_test_task1_phase1_pred.tsv',sep='\\t',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRDAa_PMuwzC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}